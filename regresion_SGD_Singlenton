import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.linalg.distributed.RowMatrix
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.regression.LinearRegressionModel
import org.apache.spark.mllib.regression.LinearRegressionWithSGD
import org.apache.spark.mllib.classification.{LogisticRegressionModel, LogisticRegressionWithLBFGS}
import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics
import org.apache.spark.mllib.evaluation.MulticlassMetrics

val data = sc.textFile("hour.csv")

val filterRDD = data.zipWithIndex().collect { case (r, i) if i != 0 => r }

val labeledPoints = filterRDD.map {line =>
 val valores = line.split(',').map(_.toDouble)
 val features = Vectors.dense(valores.init)
 val label = valores.last
 LabeledPoint(label, features)
}	

labeledPoints.cache
val numIterations = 100
val stepSize = 0.0001
 
// train a model (using singleton object)
val modelSGD = LinearRegressionWithSGD.train(labeledPoints, numIterations, stepSize)

// check the model parameters
val intercept = modelSGD.intercept
val weights = modelSGD.weights

// get actual and predicted label for each observation in the training set
val observedAndPredictedLabels = labeledPoints.map { observation =>
                val predictedLabel = modelSGD.predict(observation.features)
                (observation.label, predictedLabel)
                }

// calculate square of difference between predicted and actual label for each observation
val squaredErrors = observedAndPredictedLabels.map{case(actual, predicted) =>
                    math.pow((actual - predicted), 2)
                    }

// calculate the mean of squared errors.
val meanSquaredError = squaredErrors.mean()


//utilizando la clase RegressionMetrics: creo una instancia
import org.apache.spark.mllib.evaluation.RegressionMetrics
val regressionMetrics2 = new RegressionMetrics(observedAndPredictedLabels) 
val MSE = regressionMetrics2.meanSquaredError
val R2 = regressionMetrics2.r2
